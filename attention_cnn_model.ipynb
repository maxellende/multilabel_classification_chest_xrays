{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN model with attention block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import opendatasets as od\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import seaborn as sns\n",
    "import torchmetrics\n",
    "from torchsummary import summary\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import cv2 as cv\n",
    "import torch\n",
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Index</th>\n",
       "      <th>Patient Gender_F</th>\n",
       "      <th>Patient Gender_M</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Effusion</th>\n",
       "      <th>Emphysema</th>\n",
       "      <th>Fibrosis</th>\n",
       "      <th>Hernia</th>\n",
       "      <th>Infiltration</th>\n",
       "      <th>Mass</th>\n",
       "      <th>Nodule</th>\n",
       "      <th>Pleural_Thickening</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Pneumothorax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000001_000.png</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000001_001.png</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000001_002.png</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000003_000.png</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00000003_001.png</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112097</th>\n",
       "      <td>00030786_007.png</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112100</th>\n",
       "      <td>00030789_000.png</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112106</th>\n",
       "      <td>00030793_000.png</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112108</th>\n",
       "      <td>00030795_000.png</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112115</th>\n",
       "      <td>00030801_001.png</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51759 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Image Index  Patient Gender_F  Patient Gender_M  Atelectasis  \\\n",
       "0       00000001_000.png               0.0               1.0            0   \n",
       "1       00000001_001.png               0.0               1.0            0   \n",
       "2       00000001_002.png               0.0               1.0            0   \n",
       "4       00000003_000.png               1.0               0.0            0   \n",
       "5       00000003_001.png               1.0               0.0            0   \n",
       "...                  ...               ...               ...          ...   \n",
       "112097  00030786_007.png               1.0               0.0            0   \n",
       "112100  00030789_000.png               1.0               0.0            0   \n",
       "112106  00030793_000.png               1.0               0.0            0   \n",
       "112108  00030795_000.png               1.0               0.0            0   \n",
       "112115  00030801_001.png               0.0               1.0            0   \n",
       "\n",
       "        Cardiomegaly  Consolidation  Edema  Effusion  Emphysema  Fibrosis  \\\n",
       "0                  1              0      0         0          0         0   \n",
       "1                  1              0      0         0          1         0   \n",
       "2                  1              0      0         1          0         0   \n",
       "4                  0              0      0         0          0         0   \n",
       "5                  0              0      0         0          0         0   \n",
       "...              ...            ...    ...       ...        ...       ...   \n",
       "112097             0              1      0         0          0         0   \n",
       "112100             0              0      0         0          0         0   \n",
       "112106             0              0      0         0          0         0   \n",
       "112108             0              0      0         0          0         0   \n",
       "112115             0              0      0         0          0         0   \n",
       "\n",
       "        Hernia  Infiltration  Mass  Nodule  Pleural_Thickening  Pneumonia  \\\n",
       "0            0             0     0       0                   0          0   \n",
       "1            0             0     0       0                   0          0   \n",
       "2            0             0     0       0                   0          0   \n",
       "4            1             0     0       0                   0          0   \n",
       "5            1             0     0       0                   0          0   \n",
       "...        ...           ...   ...     ...                 ...        ...   \n",
       "112097       0             0     0       0                   1          0   \n",
       "112100       0             1     0       0                   0          0   \n",
       "112106       0             0     1       1                   0          0   \n",
       "112108       0             0     0       0                   1          0   \n",
       "112115       0             0     1       0                   0          1   \n",
       "\n",
       "        Pneumothorax  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "4                  0  \n",
       "5                  0  \n",
       "...              ...  \n",
       "112097             0  \n",
       "112100             0  \n",
       "112106             0  \n",
       "112108             0  \n",
       "112115             0  \n",
       "\n",
       "[51759 rows x 17 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/data.csv', index_col='Unnamed: 0')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Effusion</th>\n",
       "      <th>Emphysema</th>\n",
       "      <th>Fibrosis</th>\n",
       "      <th>Hernia</th>\n",
       "      <th>Infiltration</th>\n",
       "      <th>Mass</th>\n",
       "      <th>Nodule</th>\n",
       "      <th>Pleural_Thickening</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Pneumothorax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112097</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112100</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112106</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112108</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112115</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51759 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Atelectasis  Cardiomegaly  Consolidation  Edema  Effusion  Emphysema  \\\n",
       "0                 0             1              0      0         0          0   \n",
       "1                 0             1              0      0         0          1   \n",
       "2                 0             1              0      0         1          0   \n",
       "4                 0             0              0      0         0          0   \n",
       "5                 0             0              0      0         0          0   \n",
       "...             ...           ...            ...    ...       ...        ...   \n",
       "112097            0             0              1      0         0          0   \n",
       "112100            0             0              0      0         0          0   \n",
       "112106            0             0              0      0         0          0   \n",
       "112108            0             0              0      0         0          0   \n",
       "112115            0             0              0      0         0          0   \n",
       "\n",
       "        Fibrosis  Hernia  Infiltration  Mass  Nodule  Pleural_Thickening  \\\n",
       "0              0       0             0     0       0                   0   \n",
       "1              0       0             0     0       0                   0   \n",
       "2              0       0             0     0       0                   0   \n",
       "4              0       1             0     0       0                   0   \n",
       "5              0       1             0     0       0                   0   \n",
       "...          ...     ...           ...   ...     ...                 ...   \n",
       "112097         0       0             0     0       0                   1   \n",
       "112100         0       0             1     0       0                   0   \n",
       "112106         0       0             0     1       1                   0   \n",
       "112108         0       0             0     0       0                   1   \n",
       "112115         0       0             0     1       0                   0   \n",
       "\n",
       "        Pneumonia  Pneumothorax  \n",
       "0               0             0  \n",
       "1               0             0  \n",
       "2               0             0  \n",
       "4               0             0  \n",
       "5               0             0  \n",
       "...           ...           ...  \n",
       "112097          0             0  \n",
       "112100          0             0  \n",
       "112106          0             0  \n",
       "112108          0             0  \n",
       "112115          1             0  \n",
       "\n",
       "[51759 rows x 14 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_finding_labels = df.iloc[:,3:]\n",
    "df_finding_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 51759 images.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['data\\\\images_001\\\\images\\\\00000001_000.png',\n",
       "       'data\\\\images_001\\\\images\\\\00000001_001.png',\n",
       "       'data\\\\images_001\\\\images\\\\00000001_002.png', ...,\n",
       "       'data\\\\images_012\\\\images\\\\00030793_000.png',\n",
       "       'data\\\\images_012\\\\images\\\\00030795_000.png',\n",
       "       'data\\\\images_012\\\\images\\\\00030801_001.png'], dtype='<U39')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get images\n",
    "import glob\n",
    "images_names = np.array(glob.glob('data/images_*/images/*.png'))[df.index]\n",
    "N = len(images_names)\n",
    "print(\"The dataset contains {} images.\".format(N))\n",
    "images_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = []\n",
    "# IMG_SIZE = 1024 // 4\n",
    "# for x in images_names : \n",
    "#         im  = cv.resize(cv.imread(x)[:,:,0], (IMG_SIZE, IMG_SIZE))\n",
    "#         im = (im - im.min())/(im.max() - im.min())\n",
    "#         images.append(im)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_names_train, images_names_test, labels_train, labels_test = train_test_split(images_names, df_finding_labels , test_size = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "RANDOM_SEED = 42\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 128\n",
    "N_EPOCHS = 10\n",
    "\n",
    "IMG_SIZE = 1024 // 8\n",
    "N_CLASSES = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(AttentionBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, 1, kernel_size=1)  # 1x1 convolution to reduce channels\n",
    "        self.softmax = nn.Softmax(dim=2)  # Softmax along spatial dimensions\n",
    "\n",
    "    def forward(self, x):\n",
    "        attention_weights = self.conv(x)  # Calculate attention weights\n",
    "        attention_weights = self.softmax(attention_weights)  # Apply softmax\n",
    "        attended_features = x * attention_weights  # Apply element-wise multiplication\n",
    "        return attended_features\n",
    "\n",
    "# Define your CNN model with attention blocks\n",
    "class CNNWithAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNWithAttention, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.attention1 = AttentionBlock(32)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.attention2 = AttentionBlock(64)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.attention3 = AttentionBlock(128)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(128 * (IMG_SIZE // 8) * (IMG_SIZE // 8), 256)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(256, N_CLASSES)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(torch.relu(self.conv1(x)))\n",
    "        x = self.attention1(x)\n",
    "        x = self.pool2(torch.relu(self.conv2(x)))\n",
    "        x = self.attention2(x)\n",
    "        x = self.pool3(torch.relu(self.conv3(x)))\n",
    "        x = self.attention3(x)\n",
    "        x = x.view(-1, 128 * (IMG_SIZE // 8) * (IMG_SIZE // 8))\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 128, 128]             320\n",
      "         MaxPool2d-2           [-1, 32, 64, 64]               0\n",
      "            Conv2d-3            [-1, 1, 64, 64]              33\n",
      "           Softmax-4            [-1, 1, 64, 64]               0\n",
      "    AttentionBlock-5           [-1, 32, 64, 64]               0\n",
      "            Conv2d-6           [-1, 64, 64, 64]          18,496\n",
      "         MaxPool2d-7           [-1, 64, 32, 32]               0\n",
      "            Conv2d-8            [-1, 1, 32, 32]              65\n",
      "           Softmax-9            [-1, 1, 32, 32]               0\n",
      "   AttentionBlock-10           [-1, 64, 32, 32]               0\n",
      "           Conv2d-11          [-1, 128, 32, 32]          73,856\n",
      "        MaxPool2d-12          [-1, 128, 16, 16]               0\n",
      "           Conv2d-13            [-1, 1, 16, 16]             129\n",
      "          Softmax-14            [-1, 1, 16, 16]               0\n",
      "   AttentionBlock-15          [-1, 128, 16, 16]               0\n",
      "           Linear-16                  [-1, 256]       8,388,864\n",
      "          Dropout-17                  [-1, 256]               0\n",
      "           Linear-18                   [-1, 14]           3,598\n",
      "================================================================\n",
      "Total params: 8,485,361\n",
      "Trainable params: 8,485,361\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.06\n",
      "Forward/backward pass size (MB): 10.59\n",
      "Params size (MB): 32.37\n",
      "Estimated Total Size (MB): 43.02\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the CNN model with attention\n",
    "model = CNNWithAttention().to(device)\n",
    "summary(model, (1, IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n",
    "accuracy = torchmetrics.Accuracy(task=\"multilabel\", num_labels=N_CLASSES)\n",
    "f1_score = torchmetrics.F1Score(task=\"multilabel\", num_labels=N_CLASSES)\n",
    "recall = torchmetrics.Recall(task=\"multilabel\", num_labels=N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(list(zip(images_names_train, labels_train.to_numpy())) , batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "                                          \n",
    "testloader = torch.utils.data.DataLoader(list(zip(images_names_test, labels_test.to_numpy())) , batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for X_batch, y_batch in trainloader :\n",
    "#     X_batch\n",
    "#     break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainloader, testloader, start = 0) : \n",
    "\n",
    "    train_loss = []\n",
    "    train_accuracy = []\n",
    "    train_recall = []\n",
    "    train_f1 = []\n",
    "    test_loss = []\n",
    "    test_accuracy = []\n",
    "    test_recall = []\n",
    "    test_f1 = []\n",
    "    \n",
    "    for epoch in range(start, start + N_EPOCHS):  # loop over the dataset multiple times\n",
    "\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_accuracy = 0.0\n",
    "        running_recall = 0.0\n",
    "        running_f1 = 0.0\n",
    "\n",
    "        with tqdm(trainloader, unit='batch', total = len(trainloader)) as tepoch :\n",
    "            for X_batch, y_batch in tepoch:\n",
    "                tepoch.set_description(f\"Epoch {epoch+1}\")\n",
    "\n",
    "                # get inputs and labels\n",
    "                labels = y_batch.to(device).float()\n",
    "                inputs = []\n",
    "                for x in X_batch : \n",
    "                    inputs.append(cv.normalize(cv.resize(cv.imread(x)[:,:,0], (IMG_SIZE, IMG_SIZE)), 0, 255, cv.NORM_MINMAX))\n",
    "                inputs = np.array(inputs)\n",
    "                inputs = torch.Tensor(inputs).to(device).reshape((len(inputs), 1, IMG_SIZE,IMG_SIZE))\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # get statistics\n",
    "                l = loss.item()\n",
    "                running_loss += l  * len(labels) \n",
    "                acc = accuracy(outputs, labels).item()\n",
    "                running_accuracy += acc * len(labels)\n",
    "                rc = recall(outputs, labels).item()     \n",
    "                running_recall += rc * len(labels)\n",
    "                f1 = f1_score(outputs, labels).item()\n",
    "                running_f1 += f1 *len(labels)\n",
    "\n",
    "                tepoch.set_postfix(loss = l, accuracy = acc, f1 = f1, rc = rc)\n",
    "                time.sleep(1.0)\n",
    "\n",
    "\n",
    "\n",
    "                # optimize memory\n",
    "                del inputs\n",
    "                del labels\n",
    "                del outputs\n",
    "                gc.collect()\n",
    "\n",
    "        # saving model\n",
    "        path = f\"saved_models/att_model_{epoch+1}epochs.pkl\"\n",
    "        torch.save(model.state_dict(), path)\n",
    "            \n",
    "        # saving training loss and test loss \n",
    "        train_loss.append(running_loss/len(labels_train))\n",
    "        train_accuracy.append(running_accuracy/len(labels_train))\n",
    "        train_recall.append(running_recall/len(labels_train))\n",
    "        train_f1.append(running_f1/len(labels_train))\n",
    "\n",
    "        test_results = test(model, criterion, testloader)\n",
    "        test_loss.append(test_results['loss'])\n",
    "        test_accuracy.append(test_results['accuracy'])\n",
    "        test_recall.append(test_results['recall'])\n",
    "        test_f1.append(test_results['f1'])\n",
    "\n",
    "\n",
    "            \n",
    "    print('Finished Training')\n",
    "\n",
    "\n",
    "    return {'model' : model, \n",
    "            'training loss' : train_loss, \n",
    "            'training accuracy' : train_accuracy, \n",
    "            'test loss' : test_loss, \n",
    "            'test accuracy' : test_accuracy, \n",
    "            'training recall' : train_recall,\n",
    "            'training f1' : train_f1,\n",
    "            'test recall' : test_recall,\n",
    "            'test f1' : test_f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, criterion, testloader) : \n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "    running_recall = 0.0\n",
    "    running_f1 = 0.0\n",
    "    \n",
    "    with tqdm(testloader, unit='batch', total = len(testloader)) as tepoch :\n",
    "        for X_batch, y_batch in tepoch:\n",
    "            tepoch.set_description(f\"Testing\")\n",
    "            # get inputs and labels\n",
    "            labels = y_batch.to(device).float()\n",
    "            inputs = []\n",
    "            for x in X_batch : \n",
    "                inputs.append(cv.normalize(cv.resize(cv.imread(x)[:,:,0], (IMG_SIZE, IMG_SIZE)), 0, 255, cv.NORM_MINMAX))\n",
    "            inputs = np.array(inputs)\n",
    "            inputs = torch.Tensor(inputs).to(device).reshape((len(inputs), 1, IMG_SIZE,IMG_SIZE))\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            # print(outputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            l = loss.item()\n",
    "            running_loss += l  * len(labels)\n",
    "            acc = accuracy(outputs, labels).item()\n",
    "            running_accuracy += acc * len(labels)\n",
    "            rc = recall(outputs, labels).item()     \n",
    "            running_recall += rc * len(labels)\n",
    "            f1 = f1_score(outputs, labels).item()\n",
    "            running_f1 += f1 *len(labels)\n",
    "    \n",
    "            tepoch.set_postfix(loss = l, accuracy = acc, f1 = f1, rc = rc)\n",
    "            time.sleep(1)\n",
    "    \n",
    "    return {'loss' : running_loss/len(labels_test), 'accuracy' : running_accuracy/len(labels_test), 'recall' : running_recall/len(labels_test), 'f1' : running_f1/len(labels_test), 'predictions' : outputs }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/385 [00:10<?, ?batch/s, accuracy=0.624, f1=0.194, loss=0.686, rc=0.413]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x00000286C2245800>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\maxellende.julienne\\Anaconda3\\envs\\chest_xrays\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"c:\\Users\\maxellende.julienne\\Anaconda3\\envs\\chest_xrays\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1436, in _shutdown_workers\n",
      "    if self._persistent_workers or self._workers_status[worker_id]:\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'\n",
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 385/385 [39:33<00:00,  6.17s/batch, accuracy=0.85, f1=0.231, loss=0.644, rc=0.182] \n",
      "Testing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:30<00:00,  4.31s/batch, accuracy=0.865, f1=0.312, loss=0.643, rc=0.245]\n",
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 385/385 [15:01:55<00:00, 140.56s/batch, accuracy=0.902, f1=0, loss=0.602, rc=0]                \n",
      "Testing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [03:59<00:00, 11.38s/batch, accuracy=0.88, f1=0, loss=0.603, rc=0]             \n",
      "Epoch 3:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 145/385 [47:54<57:48, 14.45s/batch, accuracy=0.884, f1=0, loss=0.588, rc=0]              "
     ]
    }
   ],
   "source": [
    "results = train(model, trainloader, testloader)\n",
    "train_loss = results['training loss'] \n",
    "train_accuracy = results['training accuracy']\n",
    "test_loss = results['test loss']\n",
    "test_accuracy = results['test accuracy']\n",
    "train_recall = results['training recall']\n",
    "test_recall = results['test recall']\n",
    "train_f1 = results['training f1']\n",
    "train_recall = results['training recall']\n",
    "test_f1 = results['test f1']\n",
    "test_recall = results['test recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating baseline stats to evaluate quality of the training\n",
    "random_outputs = 1*(torch.rand(df_finding_labels.shape)>0.9)\n",
    "baseline = {}\n",
    "baseline['loss'] = criterion(random_outputs, df_finding_labels).item()\n",
    "baseline['accuracy'] = accuracy(random_outputs, df_finding_labels).item()\n",
    "baseline['recall'] = recall(random_outputs, df_finding_labels).item() \n",
    "baseline['f1'] = f1_score(random_outputs, df_finding_labels).item()\n",
    "print(baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stats(title, train_loss, train_accuracy, train_f1, train_recall, test_loss, test_accuracy, test_f1, test_recall):\n",
    "\n",
    "    epochs = np.arange(1,len(train_loss)+1)\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2, figsize = (12,10))\n",
    "    fig.suptitle(title)\n",
    "    \n",
    "    ax1.plot(epochs, train_loss, label = 'Training loss')\n",
    "    ax1.plot(epochs, test_loss, label = 'Testing loss')\n",
    "    ax1.legend(loc ='upper left')\n",
    "    ax1.set(xlabel = 'epochs', ylabel = 'loss')\n",
    "    ax1.set_title('Training and testing loss')\n",
    "\n",
    "    ax2.plot(epochs, train_accuracy, label = 'Training accuracy') \n",
    "    ax2.plot(epochs, test_accuracy, label = 'Test accuracy')\n",
    "    ax2.legend(loc ='upper left')\n",
    "    ax1.set(xlabel = 'epochs', ylabel = 'accuracy')\n",
    "    ax2.set_title('Training and testing accuracy')\n",
    "\n",
    "    ax3.plot(epochs, train_f1, label = 'Training f1-score')\n",
    "    ax3.plot(epochs, test_f1, label = 'Testing f1-score')\n",
    "    ax3.legend(loc ='upper left')\n",
    "    ax3.set(xlabel = 'epochs', ylabel = 'f1-score')\n",
    "    ax3.set_title('Training and testing f1-score')\n",
    "\n",
    "    ax4.plot(epochs, train_recall, label = 'Training recall') \n",
    "    ax4.plot(epochs, test_recall, label = 'Test recall')\n",
    "    ax4.legend(loc ='upper left')\n",
    "    ax4.set(xlabel = 'epochs', ylabel = 'recall')\n",
    "    ax4.set_title('Training and testing recall')\n",
    "\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stats('Attention model, 10 epochs', train_loss, train_accuracy, train_f1, train_recall, test_loss, test_accuracy, test_f1, test_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 10\n",
    "model_ = CNNWithAttention().to(device)\n",
    "path = f\"saved_models/att_model_{start}epochs.pkl\"\n",
    "model_.load_state_dict(torch.load(path))\n",
    "results = train(model_, trainloader, testloader, start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = test(model, criterion, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs = results['predictions'].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histo = [np.sum(outputs[:,i]) for i in range(14)]\n",
    "plt.figure(figsize = (9, 3))\n",
    "plt.stairs(histo)\n",
    "plt.xticks(np.arange(0.5,14.5), df_finding_labels.columns, rotation = 90)\n",
    "plt.title('repartition of the different cases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histo = [df_finding_labels[c].sum() for c in df_finding_labels.columns]\n",
    "plt.figure(figsize = (9, 3))\n",
    "plt.stairs(histo)\n",
    "plt.xticks(np.arange(0.5,14.5), df_finding_labels.columns, rotation = 90)\n",
    "plt.title('repartition of the different cases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_batch , targets = next(iter(testloader))\n",
    "\n",
    "# inputs = []\n",
    "# for x in X_batch : \n",
    "#     inputs.append(cv.resize(cv.imread(x)[:,:,0], (IMG_SIZE, IMG_SIZE)))\n",
    "# inputs = np.array(inputs)\n",
    "# inputs = torch.Tensor(inputs).to(device).reshape((len(inputs), 1, IMG_SIZE,IMG_SIZE))\n",
    "        \n",
    "# outputs = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.nn.functional import softmax\n",
    "# outputs_ = torch.softmax(outputs, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs_ = outputs_ > outputs_.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs_ = 1*(outputs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchmetrics import ConfusionMatrix\n",
    "# confusion_matrix = ConfusionMatrix(task=\"multilabel\", num_labels=14, normalize = 'true')\n",
    "# cm = confusion_matrix(targets, outputs_)\n",
    "# cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchmetrics import F1Score, Recall\n",
    "# f1_score = F1Score('multilabel', num_labels = 14)\n",
    "# f1 = f1_score(targets, outputs_)\n",
    "# print(f1)\n",
    "# recall_score = Recall('multilabel', num_labels = 14)\n",
    "# rc = recall_score(targets, outputs_)\n",
    "# print(rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,m in enumerate(cm) : \n",
    "#     plt.title(f'class {i+1}')\n",
    "#     sns.heatmap(m, annot = True, )\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_.detach().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def corr_matrix(y_true, y_hat) : \n",
    "targets.detach().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "y_true = targets.detach().numpy()\n",
    "y_hat = outputs_.detach().numpy()\n",
    "cm = multilabel_confusion_matrix(y_true, y_hat)\n",
    "sns.heatmap(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chest_xrays",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
